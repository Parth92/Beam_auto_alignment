{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing essential modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.polynomial.hermite import hermfit, hermval, hermval2d, hermgrid2d\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import imageio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import gaussian\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.zeros((7, 7))\n",
    "img1[1, 4] = 2.5\n",
    "img1[5, 4] = 2.5\n",
    "img1[1, 2] = 2.5\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = peak_local_max(img1, min_distance=2, exclude_border=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To avoid multiple peaks in one filter window (replaced by their avg instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_peak_per_filter(peaks, separation):\n",
    "    Updated_peaks = []\n",
    "    i = 0\n",
    "    while len(peaks>0):\n",
    "        i_pick = np.where((peaks[:,0] >= peaks[i,0]-separation) & (peaks[:,0] <= peaks[i,0]+separation) & \\\n",
    "                          (peaks[:,1] >= peaks[i,1]-separation) & (peaks[:,1] <= peaks[i,1]+separation))\n",
    "        peak1 = peaks[i_pick]\n",
    "        Len = len(peak1)\n",
    "        if Len>1:\n",
    "            peak_new = [int(np.sum(peak1[:,0])/Len), int(np.sum(peak1[:,1])/Len)]\n",
    "        else:\n",
    "            peak_new = peak1.ravel().tolist()\n",
    "        Updated_peaks.append(peak_new)\n",
    "        peaks = np.delete(peaks, i_pick, 0)\n",
    "        # print(i, 'peak_new: ', peak_new, '\\nPeaks: ', peaks)\n",
    "        i += 1\n",
    "    return Updated_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on (0,0) mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "TrainingDataFolder = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-11-07_12-09/'\n",
    "# file = 'Gen_08_time_183_Power_238.00_alignments_0.000000_0.000000_0.000000_0.000000_endMirror_0.000000.png'\n",
    "# file = 'Gen_09_time_204_Power_180.16_alignments_0.000000_0.000000_0.000000_0.000000_endMirror_0.000000.png'\n",
    "file = 'Gen_04_time_68_Power_53.14_alignments_0.000000_0.000000_0.000000_0.000000_endMirror_0.000000.png'\n",
    "# TrainingDataFolder = RepoDir + 'Data/TrainingData/'\n",
    "# file = 'HG_3_1_0_5435.png'\n",
    "img = imageio.imread(TrainingDataFolder+file)[43:243, 54:320, 0]\n",
    "plt.imshow(img, cmap=plt.cm.gray)\n",
    "plt.colorbar()\n",
    "mode = Find_mode2(img, separation1=5, corner=0, show_fig=True, show_basis=True)\n",
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dimension (n_pixl x n_pixl)\n",
    "n_pixl=128\n",
    "include_LG_data=False\n",
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "TrainingDataFolder = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-22_15-29/'\n",
    "file = 'Gen_23_time_235_Power_927.08_alignments_-0.000301_0.000066_-0.000002_-0.001734_endMirror_0.349677.png'\n",
    "# TrainingDataFolder = RepoDir + 'Data/TrainingData/'\n",
    "# file = 'HG_3_1_0_5435.png'\n",
    "img = imageio.imread(TrainingDataFolder+file)[43:243, 54:320, 0]\n",
    "plt.imshow(img, cmap=plt.cm.gray)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = Find_mode2(TrainingDataFolder+file, separation1=10, Sigma1=1, Width=10, Show_fig=True, show_peaks=True)\n",
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingDataFolder = RepoDir + 'Data/TrainingData/'\n",
    "file = 'HG_3_1_0_5435.png'\n",
    "# file = 'HG_4_4_0_9657.png'\n",
    "# file = 'HG_3_4_0_61.png'\n",
    "\n",
    "img = imageio.imread(TrainingDataFolder+file)\n",
    "# img = 255 - img\n",
    "img = img[43:243, 54:320]\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img, cmap=cm.binary_r)\n",
    "plt.colorbar()\n",
    "# mean_x = np.sum(np.sum(img, axis=0)*np.arange(128)) / np.sum(img)\n",
    "# mean_y = np.sum(np.sum(img, axis=1)*np.arange(128)) / np.sum(img)\n",
    "# plt.plot(mean_x, mean_y, '*')\n",
    "plt.show()\n",
    "# print(mean_x, mean_y)\n",
    "img1 = Thresh(img)\n",
    "plt.imshow(img1, cmap=cm.binary_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peaks = Find_Peaks(img1, show_ada_thresh=False, show_fig=True)\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_corner = peaks[:,0].argmin()\n",
    "peak_corner = peaks[i_corner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([((peaks[i,0]-peak_corner[0])**2 + (peaks[i,1]-peak_corner[1])**2) for i in range(len(peaks[:,0]))])\n",
    "print(d)\n",
    "d[d==0] = d.max()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_near1 = d.argmin()\n",
    "peak_near1 = peaks[i_near1]\n",
    "print(d)\n",
    "d[i_near1] = d.max()\n",
    "i_near2 = d.argmin()\n",
    "peak_near2 = peaks[i_near2]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis1, m1 = find_basis(peak_corner, peak_near1)\n",
    "basis2, m2 = find_basis(peak_corner, peak_near2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = peaks_to_mode(peak_corner, basis1, basis2, m1, m2, peaks, 10)\n",
    "assert (mode[0]+1)*(mode[1]+1) == len(peaks), 'Something went wrong! number of peaks \\\n",
    "inferred from mode does not match with actual number of peaks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(img)\n",
    "plt.plot(peaks[:,0], peaks[:,1], 'ko')\n",
    "# plt.plot([0,pca.components_[0,0]*20], [0,pca.components_[0,1]*20])\n",
    "# plt.plot([0,pca.components_[1,0]*20], [0,pca.components_[1,1]*20])\n",
    "\n",
    "# plt.plot([0,basis1[0]*20], [0,basis1[1]*20], 'r')\n",
    "# plt.plot([0,basis2[0]*20], [0,basis2[1]*20], 'b')\n",
    "\n",
    "kk = 4\n",
    "plt.plot([0], [0], 'r*')\n",
    "plt.plot([peak_corner[0], peak_corner[0]+(peak_near1[0]-peak_corner[0])*kk], \n",
    "         [peak_corner[1], peak_corner[1]+(peak_near1[1]-peak_corner[1])*kk], 'r')\n",
    "plt.plot([peak_corner[0], peak_corner[0]+(peak_near2[0]-peak_corner[0])*kk], \n",
    "         [peak_corner[1], peak_corner[1]+(peak_near2[1]-peak_corner[1])*kk], 'y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance of a point projected on the principal axis from origin is given by $d_i = \\frac{my_i + x_i}{\\sqrt{1+m^2}}$. The distances of these projections on a PA will form $m+1$ clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_projected_PA(PA, Point):\n",
    "    # slope of PA\n",
    "    m = PA[1] / PA[0]\n",
    "    return (m*Point[1] + Point[0]) / np.sqrt(m**2+1)\n",
    "\n",
    "def find_mode(PA, Points):\n",
    "    # find PA with lower slope\n",
    "    m = np.array([abs(PA[0,1] / PA[0,0]), abs(PA[1,1] / PA[1,0])])\n",
    "    i_PA = np.argmin(m)\n",
    "    m_min = m.pop(i_PA)\n",
    "    \n",
    "    # get projected distances of all points on this axis\n",
    "    d = []\n",
    "    for Point in Points:\n",
    "        d.append(d_projected_PA(PA[i_PA], Point))\n",
    "    M = find_peaks(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PA, Points = pca.components_, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([abs(PA[0,1] / PA[0,0]), abs(PA[1,1] / PA[1,0])])\n",
    "i_PA = np.argmin(m)\n",
    "print(i_PA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get projected distances of all points on this axis\n",
    "d = []\n",
    "for Point in Points:\n",
    "    d.append(d_projected_PA(PA[i_PA], Point))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d, np.ones(len(d)), 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = find_mode(pca.components_, peaks)\n",
    "plt.hist(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-1, 1], [-2, 1], [-3, 0], [1, 3], [2, 3], [3, 4]])\n",
    "plt.plot(X[:,0], X[:,1], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "print('PCA components: ', pca.components_)\n",
    "print('Variances: ', pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mode_0_n(Num_Peaks):\n",
    "#     return Num_Peaks - 1\n",
    "\n",
    "# def mode_m_n(Num_Peaks):\n",
    "#     return \n",
    "\n",
    "# if pca.explained_variance_ratio_.max() >= 0.8:\n",
    "#     return mode_0_n(num_peaks)\n",
    "# else:\n",
    "#     return mode_m_n(num_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,0], X[:,1], 'ko')\n",
    "plt.plot([0,pca.components_[0,0]], [0,pca.components_[0,1]])\n",
    "plt.plot([0,pca.components_[1,0]], [0,pca.components_[1,1]])\n",
    "plt.plot([0], [0], 'r*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance from the first principal axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line is represented by $Ax + By + C = 0$. Here, we have the principal axis #1 passing through origin with a slope $m = \\frac{PC^1_y}{PC^1_x}$. Thus, the line is represented by, $mx - y = 0$.\n",
    "The distance from an individual point from it is given by $\\frac{y_1 - mx_1}{\\sqrt{m^2+1^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_from_PA(PA, Point):\n",
    "    m = PA[1] / PA[0]\n",
    "    return (Point[1] - m*Point[0]) / np.sqrt(m**2+1)\n",
    "\n",
    "distances_from_PA1 = []\n",
    "peaks = X\n",
    "for point in peaks:\n",
    "    distances_from_PA1.append(distance_from_PA(pca.components_[0], point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distances_from_PA1)\n",
    "print(max(distances_from_PA1)-min(distances_from_PA1) - pca.explained_variance_[1]**0.5*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(distances_from_PA1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dimension (n_pixl x n_pixl)\n",
    "n_pixl=128\n",
    "include_LG_data=False\n",
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "# TrainingDataFolder = RepoDir + 'Data/TrainingData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(TrainingDataFolder)\n",
    "for file in files:\n",
    "    if file[-3:] != 'png':\n",
    "        files.remove(file)\n",
    "\n",
    "Labels = []\n",
    "# We have grayscale images, so while loading the images we will keep color_mode=\"grayscale\"\n",
    "Images = []\n",
    "for file in tqdm(files):\n",
    "    if not include_LG_data:\n",
    "        if file[:2] == 'LG':\n",
    "            continue\n",
    "    # training images\n",
    "    img = image.load_img(TrainingDataFolder+file, \\\n",
    "                         target_size=(n_pixl,n_pixl,1), color_mode=\"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    Images.append(img)\n",
    "    # target labels\n",
    "    Labels.append(file[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = 'HG_3_1_0_5435.png'\n",
    "# file = 'HG_4_4_0_9657.png'\n",
    "TrainingDataFolder = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-22_15-29/'\n",
    "file = 'Gen_23_time_235_Power_927.08_alignments_-0.000301_0.000066_-0.000002_-0.001734_endMirror_0.349677.png'\n",
    "img = imageio.imread(TrainingDataFolder+file)\n",
    "# img = 255 - img\n",
    "img = img[43:243, 54:320]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img, cmap=cm.binary_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit an image with mode functions and find the best fit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap=cm.binary_r)\n",
    "plt.colorbar()\n",
    "# mean_x = np.sum(np.sum(img, axis=0)*np.arange(128)) / np.sum(img)\n",
    "# mean_y = np.sum(np.sum(img, axis=1)*np.arange(128)) / np.sum(img)\n",
    "# plt.plot(mean_x, mean_y, '*')\n",
    "plt.show()\n",
    "# print(mean_x, mean_y)\n",
    "img1 = Thresh(img)\n",
    "plt.imshow(img1, cmap=cm.binary_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts at finding a method of fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.polynomial.hermite import hermfit, hermval, hermval2d, hermgrid2d\n",
    "from numpy.fft import fft2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def herm(xvals, center, scale, mode):\n",
    "    return hermval(2.**0.5*(xvals-center)/scale, mode)\n",
    "\n",
    "def HG(im_shape, X_center, Y_center, theta, mode_M, mode_N, SCALE, max_mode=10):\n",
    "    X = np.arange(im_shape[0])\n",
    "    Y = np.arange(im_shape[1])\n",
    "    xx, yy = np.meshgrid(X, Y)\n",
    "    # translation and rotation\n",
    "    X_new = (xx-X_center)*np.cos(theta) + (yy-Y_center)*np.sin(theta)\n",
    "    Y_new = -(xx-X_center)*np.sin(theta) + (yy-Y_center)*np.cos(theta)\n",
    "    # mode coeffs\n",
    "    C_m = np.zeros(max_mode)\n",
    "    C_n = np.zeros(max_mode)\n",
    "    C_m[mode_M] = 1\n",
    "    C_n[mode_N] = 1\n",
    "    # Hermite values at each point\n",
    "    HX = herm(X_new, 0., SCALE, C_m)\n",
    "    HY = herm(Y_new, 0., SCALE, C_n)\n",
    "    return (np.exp(-(X_new**2. + Y_new**2.)/SCALE**2.) * HX * HY)**2.\n",
    "\n",
    "sigma = 15.\n",
    "a = 64\n",
    "m, n = (4,0)\n",
    "IM_shape = (128, 128)\n",
    "x_c, y_c = (a, a)\n",
    "\n",
    "img2 = HG(IM_shape, x_c, y_c, np.pi/6., m, n, sigma)\n",
    "img2 /= img2.max()\n",
    "plt.imshow(img2, cmap=cm.binary_r, origin='lower')\n",
    "# plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft trial\n",
    "F = abs(fft2(img2))\n",
    "# fr = np.fft.fftfreq(128)\n",
    "fr2 = np.fft.fftshift(F)\n",
    "\n",
    "plt.imshow(fr2, cmap=cm.binary_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding + Gaussian smoothing + Local Peak collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "aa = 10\n",
    "image_max = ndi.maximum_filter(img1[:,:,0], size=aa, mode='constant')\n",
    "img_g = gaussian(img1[:,:,0],  sigma=1)\n",
    "coordinates = peak_local_max(img_g, min_distance=aa)\n",
    "\n",
    "plt.imshow(img1[:,:,0], cmap=plt.cm.gray)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(image_max)\n",
    "plt.colorbar()\n",
    "plt.figure()\n",
    "plt.imshow(img_g)\n",
    "plt.colorbar()\n",
    "# plt.autoscale(False)\n",
    "plt.plot(coordinates[:, 1],\n",
    "         coordinates[:, 0], 'r*')\n",
    "# plt.set_title('Peak local maxima', fontsize=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also Check for fitting:\n",
    "* https://numpy.org/doc/1.15/reference/generated/numpy.polynomial.hermite.hermfit.html\n",
    "* https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.hermite.hermvander2d.html#numpy.polynomial.hermite.hermvander2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.coins()  # or any NumPy array!\n",
    "edges = filters.sobel(image)\n",
    "io.imshow(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import feature\n",
    "from skimage.measure import regionprops\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.morphology import label\n",
    "\n",
    "# Load a small section of the image.\n",
    "image = data.coins()[0:95, 70:370]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3,\n",
    "                         figsize=(8, 4))\n",
    "ax0, ax1, ax2, ax3, ax4, ax5  = axes.flat\n",
    "ax0.imshow(image, cmap=plt.cm.gray)\n",
    "ax0.set_title('Original', fontsize=24)\n",
    "ax0.axis('off')\n",
    "\n",
    "# Since the image is represented by a NumPy array, we can easily perform operations such as building a histogram of the intensity values.\n",
    "\n",
    "# Histogram.\n",
    "values, bins = np.histogram(image,\n",
    "                            bins=np.arange(256))\n",
    "\n",
    "ax1.plot(bins[:-1], values, lw=2, c='k')\n",
    "ax1.set_xlim(xmax=256)\n",
    "ax1.set_yticks([0, 400])\n",
    "ax1.set_aspect(.2)\n",
    "ax1.set_title('Histogram', fontsize=24)\n",
    "\n",
    "# To divide the foreground and background, we threshold the image to produce a binary image. Several threshold algorithms are available. Here, we employ filter.threshold_adaptive where the threshold value is the weighted mean for the local neighborhood of a pixel.\n",
    "\n",
    "# Apply threshold.\n",
    "\n",
    "bw = threshold_local(image, 95, offset=-15)\n",
    "\n",
    "ax2.imshow(bw, cmap=plt.cm.gray)\n",
    "ax2.set_title('Adaptive threshold', fontsize=24)\n",
    "ax2.axis('off')\n",
    "\n",
    "# We can easily detect interesting features, such as local maxima and edges. The function feature.peak_local_max can be used to return the coordinates of local maxima in an image.\n",
    "\n",
    "# Find maxima.\n",
    "\n",
    "coordinates = peak_local_max(image, min_distance=20)\n",
    "\n",
    "ax3.imshow(image, cmap=plt.cm.gray)\n",
    "ax3.autoscale(False)\n",
    "ax3.plot(coordinates[:, 1],\n",
    "         coordinates[:, 0], 'r*')\n",
    "ax3.set_title('Peak local maxima', fontsize=24)\n",
    "ax3.axis('off')\n",
    "\n",
    "# Next, a Canny feature (feature.canny) (Canny, 1986) detects the edge of each coin.\n",
    "\n",
    "# Detect edges.\n",
    "\n",
    "edges = feature.canny(image, sigma=3,\n",
    "                     low_threshold=10,\n",
    "                     high_threshold=80)\n",
    "\n",
    "ax4.imshow(edges, cmap=plt.cm.gray)\n",
    "ax4.set_title('Edges', fontsize=24)\n",
    "ax4.axis('off')\n",
    "\n",
    "# Then, we attribute to each coin a label (morphology.label) that can be used to extract a sub-picture. Finally, physical information such as the position, area, eccentricity, perimeter, and moments can be extracted using measure.regionprops.\n",
    "\n",
    "# Label image regions.\n",
    "\n",
    "label_image = label(edges)\n",
    "\n",
    "ax5.imshow(image, cmap=plt.cm.gray)\n",
    "ax5.set_title('Labeled items', fontsize=24)\n",
    "ax5.axis('off')\n",
    "\n",
    "for region in regionprops(label_image):\n",
    "    # Draw rectangle around segmented coins.\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr),\n",
    "                              maxc - minc,\n",
    "                              maxr - minr,\n",
    "                              fill=False,\n",
    "                              edgecolor='red',\n",
    "                              linewidth=2)\n",
    "    ax5.add_patch(rect)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting in Fourier Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image dimension (n_pixl x n_pixl)\n",
    "n_pixl=128\n",
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "\n",
    "# TrainingDataFolder1 = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-22_15-29/'\n",
    "# file1 = 'Gen_23_time_235_Power_927.08_alignments_-0.000301_0.000066_-0.000002_-0.001734_endMirror_0.349677.png'\n",
    "TrainingDataFolder1 = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-26_13-07/'\n",
    "file1 = 'Gen_11_time_408_Power_1594.09_alignments_0.000003_0.000019_-0.000030_0.000126_endMirror_0.000004.png'\n",
    "img1 = imageio.imread(TrainingDataFolder1+file1)[43:243, 54:320, 0]\n",
    "\n",
    "img1 = gaussian(img1,  sigma=1)\n",
    "img1 = Thresh(img1)\n",
    "\n",
    "f1 = np.fft.fft2(img1)\n",
    "fshift1 = np.fft.fftshift(f1)\n",
    "magnitude_spectrum1 = np.abs(fshift1)\n",
    "magnitude_spectrum1 = 20*np.log(magnitude_spectrum1)\n",
    "magnitude_spectrum1 = np.asarray(magnitude_spectrum1, dtype=np.float32)\n",
    "# img_and_magnitude1 = np.concatenate((img1, magnitude_spectrum1), axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1)\n",
    "plt.subplot(122)\n",
    "plt.imshow(magnitude_spectrum1)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_spectrum1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading simulated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dimension (n_pixl x n_pixl)\n",
    "n_pixl=128\n",
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "\n",
    "TrainingDataFolder = RepoDir + 'Data/TrainingData/'\n",
    "# file = 'HG_3_1_0_5435.png'\n",
    "file = 'HG_3_0_0_12.png'\n",
    "img = imageio.imread(TrainingDataFolder+file)\n",
    "img = 255 - img\n",
    "\n",
    "f = np.fft.fft2(img)\n",
    "fshift = np.fft.fftshift(f)\n",
    "magnitude_spectrum = np.abs(fshift)\n",
    "# magnitude_spectrum = 20*np.log(magnitude_spectrum)\n",
    "magnitude_spectrum = np.asarray(magnitude_spectrum, dtype=np.float32)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(magnitude_spectrum)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.max(magnitude_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1000)\n",
    "y = np.arange(1000)\n",
    "xx, yy = np.meshgrid(x, y, sparse=True)\n",
    "z = np.sin((xx/100)**2 + (yy/100)**2) / ((xx/100)**2 + (yy/100)**2)\n",
    "plt.figure(figsize=(7,7))\n",
    "h = plt.pcolormesh(x,y,z,cmap=plt.cm.binary_r)\n",
    "plt.plot([400], [200], 'y*')\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(z,cmap=plt.cm.binary_r)\n",
    "plt.plot([400], [200], 'y*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image moments and successive rotation fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 2.5e1\n",
    "a = 100\n",
    "m, n = (3,0)\n",
    "IM_shape = (266, 200)\n",
    "x_c, y_c = (a, a)\n",
    "theta = 0#np.pi/2.4\n",
    "\n",
    "img2 = HG(IM_shape, x_c, y_c, theta, m, n, sigma)\n",
    "\n",
    "img2 = gaussian(img2,  sigma=1)\n",
    "img2 = Thresh(img2)\n",
    "# normalized model\n",
    "img2 /= img2.sum()\n",
    "\n",
    "Xm, Ym = moment1(img2)\n",
    "# plt.figure(figsize=(10,10))\n",
    "Xsigma, Ysigma, s1, s2 = moment2(img2, Xm, Ym, np.tan(theta), 1., show_im=True)\n",
    "\n",
    "plt.imshow(img2, cmap=plt.cm.binary_r)\n",
    "plt.colorbar()\n",
    "plt.plot(Xm, Ym, 'r*')\n",
    "print(Xsigma, Ysigma, s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Thresh(IMG1, thresh=0.5):\n",
    "    IMG = IMG1.copy()\n",
    "    IMG[IMG < thresh*IMG.max()] = 0.\n",
    "    IMG[IMG >= thresh*IMG.max()] = 1.\n",
    "    return IMG\n",
    "\n",
    "def herm(xvals, center, scale, mode):\n",
    "    return hermval(2.**0.5 * (xvals-center)/scale, mode)\n",
    "\n",
    "def HG(im_shape, X_center, Y_center, theta, mode_M, mode_N, SCALE, max_mode=10):\n",
    "    X = np.arange(im_shape[1])\n",
    "    Y = np.arange(im_shape[0])\n",
    "    xx, yy = np.meshgrid(X, Y)\n",
    "    # translation and rotation\n",
    "    X_new = (xx-X_center)*np.cos(theta) + (yy-Y_center)*np.sin(theta)\n",
    "    Y_new = -(xx-X_center)*np.sin(theta) + (yy-Y_center)*np.cos(theta)\n",
    "    # mode coeffs\n",
    "    C_m = np.zeros(max_mode)\n",
    "    C_n = np.zeros(max_mode)\n",
    "    C_m[mode_M] = 1\n",
    "    C_n[mode_N] = 1\n",
    "    # Hermite values at each point\n",
    "    HX = herm(X_new, 0., SCALE, C_m)\n",
    "    HY = herm(Y_new, 0., SCALE, C_n)\n",
    "    return (np.exp(-(X_new**2. + Y_new**2.)/SCALE**2.) * HX * HY)**2.\n",
    "\n",
    "def d_frm_orig_along_m(XX, YY, M):\n",
    "    if not (isinstance(XX, float) & isinstance(YY, float)):\n",
    "        XX, YY = np.meshgrid(XX, YY)\n",
    "    l = XX**2. + M**2. * YY**2. + 2.*M*XX*YY\n",
    "    l /= (1+M**2.)\n",
    "    l = np.round(l, 3) # numerical errors making values negative (of order: 10^-12 or lower)\n",
    "    l **= 0.5\n",
    "    return l\n",
    "\n",
    "def Spread_n_mean(Img, m):\n",
    "    # distance of all pts from origin along slope\n",
    "    d_img = d_frm_orig_along_m(np.arange(Img.shape[1]), np.arange(Img.shape[0]), m) # columns are x values and rows are y values\n",
    "    # extreme points\n",
    "    Img2 = Img.copy()\n",
    "    Img2[Img2 > 0] = 1\n",
    "    imm = (d_img * Img2)\n",
    "    # plt.imshow(imm)\n",
    "    pt_max = np.where(imm == imm.max())\n",
    "    pt_min = np.where(imm == imm[imm > 0.].min())\n",
    "    # plt.plot(pt_min[1].sum()/len(pt_min[1]), pt_min[0].sum()/len(pt_min[0]), 'r*')\n",
    "    # plt.plot(pt_max[1].sum()/len(pt_max[1]), pt_max[0].sum()/len(pt_max[0]), 'g*')\n",
    "    # plt.show()\n",
    "    pt_max = np.array([pt_max[1].sum()/len(pt_max[1]), pt_max[0].sum()/len(pt_max[0])]) # the first index is row number which is y-axis value\n",
    "    pt_min = np.array([pt_min[1].sum()/len(pt_min[1]), pt_min[0].sum()/len(pt_min[0])])\n",
    "    # mean and spread of these points\n",
    "    mean = (pt_min+pt_max)/2\n",
    "    spread = (d_img[Img>0].max() - d_img[Img>0].min())/2.\n",
    "    return mean, spread\n",
    "\n",
    "def moments(Img1, Slope, scale, show_im=False):\n",
    "    # moments\n",
    "    Mean, sprd1 = Spread_n_mean(Img1, Slope)\n",
    "    if Slope == 0.:\n",
    "        Slope = 1e-10\n",
    "    _, sprd2 = Spread_n_mean(Img1, -1./Slope)\n",
    "    xmean = Mean[0]\n",
    "    ymean = Mean[1]\n",
    "    if show_im:\n",
    "        # scale\n",
    "        sin = scale*Slope/np.sqrt(1+Slope**2.)\n",
    "        cos = scale/np.sqrt(1+Slope**2.)\n",
    "        plt.plot(xmean, ymean, 'r*')\n",
    "        plt.plot(xmean-sprd1*cos, ymean-sprd1*sin, 'yo')\n",
    "        plt.plot(xmean+sprd1*cos, ymean+sprd1*sin, 'yo')\n",
    "        plt.plot(xmean-sprd2*sin, ymean+sprd2*cos, 'go')\n",
    "        plt.plot(xmean+sprd2*sin, ymean-sprd2*cos, 'go')\n",
    "    return sprd1, sprd2, xmean, ymean\n",
    "\n",
    "# def moment1(Img):\n",
    "#     x = np.arange(Img.shape[1])\n",
    "#     y = np.arange(Img.shape[0])\n",
    "#     xmean = np.average(x, weights=Img.sum(axis=0))\n",
    "#     ymean = np.average(y, weights=Img.sum(axis=1))\n",
    "#     return xmean, ymean\n",
    "\n",
    "# def Sigma(Img, Xmean, Ymean, m):\n",
    "#     # distance of mean pt from origin along slope\n",
    "#     Dmean = d_frm_orig_along_m(Xmean, Ymean, m)\n",
    "#     # distance of all pts from origin along slope\n",
    "#     d_img = d_frm_orig_along_m(np.arange(Img.shape[1]), np.arange(Img.shape[0]), m) # columns are x values and rows are y values\n",
    "#     d_img -= Dmean\n",
    "#     # 2nd moment\n",
    "#     sigma = d_img**2. * Img / Img.sum()\n",
    "#     sigma = sigma.sum()\n",
    "#     sigma **= 0.5\n",
    "#     # max spread\n",
    "#     spread = (d_img[Img>0].max() - d_img[Img>0].min())/2.\n",
    "#     return sigma, spread, d_img[Img>0]\n",
    "\n",
    "# def moment2(Img1, xmean, ymean, Slope, scale, show_im=False):\n",
    "#     sig1, sprd1, dd1 = Sigma(Img1, xmean, ymean, Slope)\n",
    "#     if Slope == 0.:\n",
    "#         Slope = 1e-10\n",
    "#     sig2, sprd2, dd2 = Sigma(Img1, xmean, ymean, -1./Slope)\n",
    "#     if show_im:\n",
    "#         # center\n",
    "#         plt.plot(xmean, ymean, 'r*')\n",
    "#         # scale\n",
    "#         sin = scale*Slope/np.sqrt(1+Slope**2.)\n",
    "#         cos = scale/np.sqrt(1+Slope**2.)\n",
    "#         s1 = sprd1\n",
    "#         s2 = sprd2\n",
    "#         plt.plot(xmean-s1*cos, ymean-s1*sin, 'yo')\n",
    "#         plt.plot(xmean+s1*cos, ymean+s1*sin, 'yo')\n",
    "#         plt.plot(xmean-s2*sin, ymean+s2*cos, 'bo')\n",
    "#         plt.plot(xmean+s2*sin, ymean-s2*cos, 'bo')\n",
    "#     return sig1, sig2, sprd1, sprd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_spreads(Img, Thetas1):\n",
    "    uniq_thetas = np.unique(Thetas1)\n",
    "    Spreads = np.zeros((max_m+1, max_n+1, Thetas1.shape[2]))\n",
    "    for Theta in uniq_thetas:\n",
    "        # indices for Theta\n",
    "        i_theta = np.where(Thetas1 == Theta)\n",
    "        spread_im1, spread_im2, _, _ = moments(Img, np.tan(Theta), 1, show_im=False)\n",
    "        if spread_im1 > spread_im2:\n",
    "            Spreads[i_theta] = spread_im1\n",
    "        else:\n",
    "            Thetas1[i_theta] = Theta+np.pi/2.\n",
    "            Spreads[i_theta] = spread_im2\n",
    "    return Thetas1, Spreads\n",
    "\n",
    "def get_mode_array(X_c, Y_c, spreads2, Thetas2, IM_shape=(200,266)):\n",
    "    Sim_modes = np.zeros((max_m+1, max_n+1, IM_shape[0], IM_shape[1]))\n",
    "    for m in range(max_m+1):\n",
    "        for n in range(min(max_n+1, m+1)):\n",
    "            Model = HG(IM_shape, X_c, Y_c, Thetas2[m,n], m, n, initial_scale*spreads2[m,n]/mode_spreads[m,n])\n",
    "            Model = gaussian(Model,  sigma=1)\n",
    "            Model = Thresh(Model)\n",
    "            # normalized model\n",
    "            Model /= Model.sum()\n",
    "            Sim_modes[m,n,:,:] = Model\n",
    "    return Sim_modes\n",
    "\n",
    "def calculate_fit(Im_array, Sim_modes):\n",
    "    Fit = ((Im_array>0) & (Sim_modes>0)).sum(axis=3).sum(axis=2) - ((Im_array>0) ^ (Sim_modes>0)).sum(axis=3).sum(axis=2)\n",
    "#     Fit = (Im_array * Sim_modes).sum(axis=3).sum(axis=2) - np.abs(Im_array - Sim_modes).sum(axis=3).sum(axis=2)\n",
    "    return Fit\n",
    "\n",
    "def fit_modes(Thetas, Img, x_c, y_c, show_im=False):\n",
    "    # check spreads along thetas. Change theta to theta+pi/2 if spread2>spread1\n",
    "    Thetas, spreads = get_max_spreads(Img, Thetas)\n",
    "    # create image array to match mode array dimentions\n",
    "    im_array = np.expand_dims(Img, axis=0)\n",
    "    im_array = np.repeat(im_array, max_m+1, axis=0)\n",
    "    im_array = np.expand_dims(im_array, axis=1)\n",
    "    im_array = np.repeat(im_array, max_n+1, axis=1)\n",
    "    # fit values for each mode for all theta vals\n",
    "    fit = np.zeros((max_m+1, max_n+1, Thetas.shape[2]))\n",
    "    for i in range(Thetas.shape[2]):\n",
    "        # create new mode array using spreads and mean position\n",
    "        sim_modes = get_mode_array(x_c, y_c, spreads[:,:,i], Thetas[:,:,i])\n",
    "        # fit\n",
    "        fit[:,:,i] = calculate_fit(im_array, sim_modes)\n",
    "    return fit\n",
    "\n",
    "def pick_best(Fitting_factor, Thetas):\n",
    "    Best_fit = Fitting_factor[:,:,0]\n",
    "    Best_theta = Thetas[:,:,0]\n",
    "    for i in range(Thetas.shape[2]-1):\n",
    "        i_best = Best_fit < Fitting_factor[:,:,i+1]\n",
    "        Best_fit[i_best] = Fitting_factor[:,:,i+1][i_best]\n",
    "        Best_theta[i_best] = Thetas[:,:,i+1][i_best]\n",
    "    return Best_fit, Best_theta\n",
    "\n",
    "def find_mode_spreads(Max_M, Max_N, IM_shape=(200,266)):\n",
    "    Mode_spreads = np.zeros((Max_M+1, Max_N+1))\n",
    "    for M in range(Max_M+1):\n",
    "        for N in range(min(Max_N+1, M+1)):\n",
    "            mode_model = HG(IM_shape, IM_shape[1]/2, IM_shape[0]/2, 0., M, N, initial_scale)\n",
    "            mode_model = gaussian(mode_model,  sigma=1)\n",
    "            mode_model = Thresh(mode_model)\n",
    "            # calculate spread and feed that value\n",
    "            sprd1, _, _, _ = moments(mode_model, 0., 1, show_im=False)\n",
    "            Mode_spreads[M,N] = sprd1\n",
    "    return Mode_spreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only dep on spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dimension (n_pixl x n_pixl)\n",
    "n_pixl=128\n",
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "\n",
    "# TrainingDataFolder1 = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-22_15-29/'\n",
    "# file1 = 'Gen_23_time_235_Power_927.08_alignments_-0.000301_0.000066_-0.000002_-0.001734_endMirror_0.349677.png'\n",
    "# file1 = 'Gen_11_time_408_Power_1594.09_alignments_0.000003_0.000019_-0.000030_0.000126_endMirror_0.000004.png'\n",
    "TrainingDataFolder1 = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-26_13-07/'\n",
    "file1 = 'Gen_21_time_749_Power_540.16_alignments_0.000000_-0.000000_0.000000_-0.000000_endMirror_-0.000004.png'\n",
    "img1 = imageio.imread(TrainingDataFolder1+file1)[43:243, 54:320, 0]\n",
    "\n",
    "img1 = gaussian(img1,  sigma=1)\n",
    "img1 = Thresh(img1)\n",
    "\n",
    "s1, s2, Xm, Ym = moments(img1, np.tan(np.pi/13), 1, show_im=True)\n",
    "\n",
    "print(s1, s2)\n",
    "plt.imshow(img1, cmap=plt.cm.binary_r)\n",
    "plt.plot(Xm, Ym, 'r*')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_m = 8\n",
    "max_n = 1\n",
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "no_iters = 4\n",
    "\n",
    "# scale used to create models and record their spreads for once\n",
    "initial_scale = 3e1\n",
    "# find mode spreads\n",
    "mode_spreads = find_mode_spreads(max_m, max_n)\n",
    "\n",
    "# TrainingDataFolder1 = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-22_15-29/'\n",
    "# file1 = 'Gen_23_time_235_Power_927.08_alignments_-0.000301_0.000066_-0.000002_-0.001734_endMirror_0.349677.png'\n",
    "TrainingDataFolder1 = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-26_13-07/'\n",
    "# file1 = 'Gen_21_time_749_Power_540.16_alignments_0.000000_-0.000000_0.000000_-0.000000_endMirror_-0.000004.png'\n",
    "file1 = 'Gen_14_time_510_Power_839.02_alignments_-0.000000_0.000019_-0.000000_0.000009_endMirror_0.000000.png'\n",
    "img1 = imageio.imread(TrainingDataFolder1+file1)[43:243, 54:320, 0]\n",
    "# Preprocess\n",
    "img1 = gaussian(img1,  sigma=1)\n",
    "img1 = Thresh(img1)\n",
    "\n",
    "img1 /= img1.sum()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(img1, cmap=plt.cm.binary_r)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# get the modes in image\n",
    "thetas = np.array([0., np.pi/4., np.pi/2.])\n",
    "delta_theta = thetas[1] - thetas[0]\n",
    "thetas = np.expand_dims(thetas, axis=0)\n",
    "thetas = np.repeat(thetas, max_m+1, axis=0)\n",
    "thetas = np.expand_dims(thetas, axis=1)\n",
    "thetas = np.repeat(thetas, max_n+1, axis=1)\n",
    "\n",
    "old_best_fit = np.zeros((max_m+1, max_n+1))\n",
    "_, _, im_xc, im_yc = moments(img1, np.tan(0.), 1, show_im=False)\n",
    "\n",
    "for i in range(no_iters):\n",
    "    delta_theta /= 2.\n",
    "    if i == 0:\n",
    "        fitting_factor = fit_modes(thetas, img1, im_xc, im_yc, show_im=False)\n",
    "        # check the best theta\n",
    "        best_fit, best_theta = pick_best(fitting_factor, thetas)\n",
    "    else:\n",
    "        fitting_factor = fit_modes(thetas, img1, im_xc, im_yc, show_im=False)\n",
    "        # append the prev best fit data\n",
    "        fitting_factor = np.append(fitting_factor, np.expand_dims(best_fit, axis=2), axis=2)\n",
    "        thetas = np.append(thetas, np.expand_dims(best_theta, axis=2), axis=2)\n",
    "        # check the best theta\n",
    "        best_fit, best_theta = pick_best(fitting_factor, thetas)\n",
    "    thetas = np.zeros((best_theta.shape[0], best_theta.shape[1], 2))\n",
    "    thetas[:,:,0] = best_theta-delta_theta\n",
    "    thetas[:,:,1] = best_theta+delta_theta\n",
    "\n",
    "# get best fit mode\n",
    "i_best = np.where(best_fit == best_fit.max())\n",
    "print('Theta: ', best_theta[i_best]*180/np.pi, 'Fit: ', best_fit[i_best], 'Mode: ', (i_best[0][0], i_best[1][0]))    \n",
    "\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mode finding with autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = HG(img1.shape, im_xc, im_yc, best_theta[i_best][0], i_best[0][0], i_best[1][0], 30)\n",
    "Model = gaussian(Model,  sigma=1)\n",
    "Model = Thresh(Model)\n",
    "plt.imshow(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Comparison with prev mode finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shreejit/WORK/Beam_auto_alignment/src\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import *\n",
    "RepoDir = '~/WORK/Beam_auto_alignment/'\n",
    "TrainingDataFolder1 = RepoDir + 'Data/Actual_cavity_Fittest_points_per_gen_2019-07-26_13-07/'\n",
    "# file1 = 'Gen_21_time_749_Power_540.16_alignments_0.000000_-0.000000_0.000000_-0.000000_endMirror_-0.000004.png'\n",
    "file1 = 'Gen_14_time_510_Power_839.02_alignments_-0.000000_0.000019_-0.000000_0.000009_endMirror_0.000000.png'\n",
    "img1 = imageio.imread(TrainingDataFolder1+file1)[43:243, 54:320, 0]\n",
    "# Preprocess\n",
    "img1 = gaussian(img1,  sigma=1)\n",
    "img1 = Thresh(img1)\n",
    "\n",
    "img1 /= img1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3187522888183594\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for i in range(200):\n",
    "    mode_new = Find_mode2(img1, separation1=10, corner=0, show_fig=False, show_basis=False)\n",
    "print(time.time()-t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
